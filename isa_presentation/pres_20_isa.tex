\documentclass[11pt]{beamer}
% \documentclass[11pt,handout]{beamer}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{float, afterpage, rotating, graphicx}
\usepackage{epstopdf}
\usepackage{longtable, booktabs, tabularx}
\usepackage{fancyvrb, moreverb, relsize}
\usepackage{eurosym, calc, chngcntr}
\usepackage{amsmath, amssymb, amsfonts, amsthm, bm} 

\usepackage[backend=biber, natbib=true, bibencoding=inputenc, bibstyle=authoryear-ibid, citestyle=authoryear-comp, maxcitenames=3, maxbibnames=10]{biblatex}
\setlength{\bibitemsep}{1.5ex}
\addbibresource{refs.bib}

\hypersetup{colorlinks=true, linkcolor=black, anchorcolor=black, citecolor=black, filecolor=black, menucolor=black, runcolor=black, urlcolor=black}

\setbeamertemplate{footline}[frame number]
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{frametitle}{\centering\vspace{1ex}\insertframetitle\par}


\begin{document}

\title{SEMIPARAMETRIC SINGLE INDEX MODELS: Ichimura and Klein and Spady's models}

\author[Li Marques Sun] % \& others]
{
{\bf Project Module Econometrics and Statistics}\\
{\small Li Marques Sun}\\[1ex]
%{\bf Add other authors}\\
%{\small and affilitations}\\[1ex]
}

\date{
{\bf Bonn}\\
{\small January, 18}
}


\begin{frame}
    \titlepage
    \note{~}
\end{frame}


\begin{frame}[t]
    \frametitle{Ichimura's (1993) method}
For known $g$ a nonlinear least squares (NLS) method can be used to estimate $\beta_0$ by minimizing:
\begin{equation}
S_n(\beta) = \frac{1}{n}\sum_{i = 1}^n\big[Y_i - g(X_i'\beta)\big]^2
\end{equation}
with respect to $\beta$. However, for $g$ unknown and for a given $\beta$ we can estimate:
\begin{equation}
G(X_i'\beta) \stackrel{def}{=} E(Yi|X_i'\beta) = E[g(X_i'\beta_0)|X_i'\beta].
\end{equation}
Given this, the weighted NLS problem is as follows:
\begin{equation}
S_n(\beta) = \frac{1}{n} \sum_{i=1}^{n}  [Y_i - \hat{G}_{-i}(X_i'\beta)]^2w(x_i)\mathbf{1}{(X_i \in A_n)}
\end{equation}
where $\hat{G}_{-i}(X_i'\beta)$ is a leave-one-out Nadaraya-Watson kernel estimator,  $\mathbf{1}{(Xi \in A_n)}$ is a trimming function and $w(x_i)$ is a weighting function.

\end{frame}



\begin{frame}[t]
    \frametitle{Ichimura's (1993) method}
    
\begin{theorem}
According to Ichimura (1993) we have,



\[ \sqrt{n}(\hat{\beta}_n - \beta_0) \stackrel{d}{\rightarrow} N(0,\Omega_I), \] where $\Omega_I = V^{-1}\Sigma V^{-1}$, and

\[\Sigma = E\{w(X_i)^2\sigma^2(X_i)(g_i^{(1)})^2(X_i - E_A(X_i|X_i'\beta_0)) \times (X_i - E_A(X_i|X_i'\beta_0))'\},\]

with $g_i^{(1)} = [\partial g(v)/\partial v]|_{v = X_i'\beta_0}, E_A(X_i|v) = E(X_i|x_A'\beta_0 = v)$ with $x_A$ having the distribution of $X_i$ conditional on $Xi \in A_\delta$, and

\[ V = E[w(X_i)(g_i^{(1)})^2(X_i - E_A(X_i|X_i'\beta_0))(X_i - E_A(X_i|X_i'\beta_0))'].\]

\end{theorem}
\end{frame}


\begin{frame}[t]
    \frametitle{Ichimura's (1993) method}

\textbf{Intuition}: Assume $\beta_n - \beta_0 = O(n^{-\frac{1}{2}})$, $\hat{\beta}_n - \beta_0 = O_p(n^{-\frac{1}{2}})$, $ \hat{G}_{-i}(X_i'\beta_n) = G(X_i'\beta_n) + o_p(1)$ and $\hat{G}_{-i}(X_i'\beta_0) = g(X_i'\beta_0) + o_p(1)$. 
\begin{itemize}

	\item It can be shown $ S_{n}(\beta_n) = \frac{1}{n}\sum_i \{ g(X_i'\beta_0) - E[g(X_i'\beta_0)|X_i'\beta_n] +  \epsilon_i\}^2 + o_p(1)$.
	
	\item With two Taylor expansions we have $g(X_i'\beta_0) - E[g(X_i'\beta_0)|X_i'\beta_n)] = g^{(1)}(X_i'\beta_n)( X_i - E[X_i'|X_i'\beta_n)(\beta_0 - \beta_n) + o_p(1)$.
	
	\item Minimize $S_n$ in order to $\hat{\beta}_n$ .

\end{itemize}

\end{frame}

\begin{frame}[t]
    \frametitle{Ichimura's (1993) method}
  
	\begin{enumerate}

		\item \textbf{Bandwidth Selection}:
Ichimura requires $h_n=O(n^{-\frac{1}{5}})$. H{\"a}rdle et al. (1993) suggest an empirical way of selecting the bandwidth for optimal smoothing of both $g$ and $\beta$.
		\item \textbf{Weight Function}:
	In case data is heroskedastic, use analogue of Feasible Generalized Least Squares. Under certain regularity conditions, the efficiency bound for the single index model with unknown $g$ and using only data for which $X \in A_{\delta}$ is $\Omega_I$ with $w(x) = \frac{1}{\sigma^2(x)}$. The efficiency bound is then
		\begin{equation}
\Omega_{SI} = \left\{ E\left[\frac{1}{\sigma^2(x)}\frac{\partial}{\partial \beta}
 G(X'\beta,\beta)\frac{\partial}{\partial \beta} G(X'\beta,\beta) \right] \right\}^{-1}.
		\end{equation}
For unknown $\sigma^2(x)$, a consistent estimator is used that follows a two-step procedure.
		\item \textbf{Main Problem}: Uses iterative method, particularly difficult if the objective function is multimodal or nonconvex.

	\end{enumerate}

\end{frame}

\begin{frame}[t]
    \frametitle{Klein and Spady's (1993) method}
The model is defined as $Y_i =  \mathbf{1}{(X_i'\beta \geq \epsilon_i)}$, where $\epsilon$ is a random disturbance.
Thus, the maximum-likelihood problem is as follows:
\begin{equation}
\mathcal{L}_n(\beta) = \frac{1}{n}\sum_{i=1}^n \tau_{i}\{ (1 - Y_i)ln[ 1 - \hat{G}_{-i}(X_i'\beta)] +  Y_iln[\hat{G}_{-i}(X_i'\beta)]\}.
\end{equation}
\begin{theorem}
According to Klein and Spady (1993),
\[\sqrt{n}(\hat{\beta}_{n} - \beta_0) \stackrel{d}{\rightarrow} N(0,\Omega_{KS}),
\]
where $ \Omega_{KS} = \left\{ E\left[\frac{\partial}{\partial \beta}
 G(X_i'\beta)\frac{\partial}{\partial \beta} G(X_i'\beta)'\frac{1}{g(X_i'\beta_0)(1 - g(X_i'\beta_0))} \right]\right\}^{-1} $
 and $\Omega_{KS} = \Omega_{SI}$, i.e., the estimator is asymptotically efficient.

\end{theorem}
\end{frame}

\begin{frame}[t]
    \frametitle{Klein and Spady's (1993) method}
%Assume $\beta_n - \beta_0 = O(n^{-\frac{1}{2}})$, $\hat{\beta}_n - \beta_0 = O_p(n^{-\frac{1}{2}})$. By first using a Taylor expansion of $g(X_i'\beta_0) - E_A[g(X_i'\beta_0)|X_i'\beta)]$ it can be shown:

\begin{enumerate}
	\item \textbf{Bandwidth Selection}: Klein and Spady require $ n^{-\frac{1}{6}} < h_n < n^{-\frac{1}{8}}$. H{\"a}rdle et al.'s (1993) solution can potentially be applied here as well.
	\item \textbf{Main Problem}: Same as for Ichimura's method.
	\item \textbf{Comparison between Ichimura's and Klein and Spady's model}:
	Klein and Spady's model seems more appropriate for the binary choice model case, from a theoretical perspective. Ichimura's model uses a weight function to correct for heteroskedasticity. However, Klein and Spady's model is fully efficient in the sense that it reaches the semiparametric efficiency bound.
\end{enumerate}
\end{frame}
% Print black screen only in presentation mode for finishing up.
\mode<beamer> {
    \beamersetaveragebackground{black}
    \begin{frame}
        \frametitle{}
    \end{frame}

    \beamersetaveragebackground{white}
}

\begin{frame}[allowframebreaks]
    \frametitle{References}
    \renewcommand{\bibfont}{\normalfont\footnotesize}
    \printbibliography
\end{frame}

\end{document}
